{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74b5be3",
   "metadata": {},
   "source": [
    "# Train and eval models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190d32a",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "172b5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter, OrderedDict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "525318e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bb978f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DefaultDataCollator,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34f24c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/emiliomarinone/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d724d43fa1ac40ec9777bb84e9639d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = \"ag_news\"\n",
    "dataset = load_dataset(dataset_id)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde1c0f",
   "metadata": {},
   "source": [
    "Since the dataset does not have an eval split, we generate it from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4c89d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/emiliomarinone/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-a83c7d61fb1af540.arrow and /Users/emiliomarinone/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-e6ec95f998f1a335.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 108000\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train_ds = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split_train_ds[\"train\"],\n",
    "    \"eval\": split_train_ds[\"test\"],\n",
    "    \"test\": dataset[\"test\"]\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d644d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
     ]
    }
   ],
   "source": [
    "label_class = dataset[\"train\"].features[\"label\"]\n",
    "label_names = label_class.names\n",
    "num_labels = label_class.num_classes\n",
    "print(f\"{num_labels} labels: {label_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a13dd2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=4, names=['World', 'Sports', 'Business', 'Sci/Tech'], id=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f119bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_intents = {k: v for v, k in enumerate(label_names)}\n",
    "inverse_encoded_intents = {k: v for v, k in encoded_intents.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ddb07ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'World': 0, 'Sports': 1, 'Business': 2, 'Sci/Tech': 3}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc18854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_encoded_intents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8d51f",
   "metadata": {},
   "source": [
    "## Quick check to verify the dataset is not corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6f44674",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd379197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset[\"train\"][:]\n",
    "train_df[\"label_name\"] = train_df[\"label\"].apply(label_class.int2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de7d7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dataset[\"test\"][:]\n",
    "test_df[\"label_name\"] = test_df[\"label\"].apply(label_class.int2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4179bfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35745</th>\n",
       "      <td>UPDATE: Australia #39;s WMC Ups Stakes In Xstr...</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Monday #39;s AL Capsules Bruce Chen pitched hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8703</th>\n",
       "      <td>Intel test chip boasts technology to add to sp...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>NBA snubs hearing with arbitrator Ron Artest t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52586</th>\n",
       "      <td>Users say Microsoft's Money is broke Glitches ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label label_name\n",
       "35745  UPDATE: Australia #39;s WMC Ups Stakes In Xstr...      2   Business\n",
       "1123   Monday #39;s AL Capsules Bruce Chen pitched hi...      1     Sports\n",
       "8703   Intel test chip boasts technology to add to sp...      3   Sci/Tech\n",
       "25464  NBA snubs hearing with arbitrator Ron Artest t...      1     Sports\n",
       "52586  Users say Microsoft's Money is broke Glitches ...      3   Sci/Tech"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8ee3e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>Trying to recapture glory days With two Super ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>Analysis: Iran #39;s missile capabilities Iran...</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>Final respects paid to Arafat Palestinians pay...</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>Bush, Kerry Trade Barbs Following Debate ALLEN...</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>Napster Mobile December 10, 2004 - Remember Na...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label label_name\n",
       "1406  Trying to recapture glory days With two Super ...      1     Sports\n",
       "3315  Analysis: Iran #39;s missile capabilities Iran...      0      World\n",
       "5641  Final respects paid to Arafat Palestinians pay...      0      World\n",
       "2956  Bush, Kerry Trade Barbs Following Debate ALLEN...      0      World\n",
       "7126  Napster Mobile December 10, 2004 - Remember Na...      3   Sci/Tech"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca4ea976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business    27100\n",
       "World       26991\n",
       "Sports      26966\n",
       "Sci/Tech    26943\n",
       "Name: label_name, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8a63d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business    1900\n",
       "Sci/Tech    1900\n",
       "Sports      1900\n",
       "World       1900\n",
       "Name: label_name, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"label_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4572835",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3963937",
   "metadata": {},
   "source": [
    "## Split and tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be9c7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a7fc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ad4bdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3b67d6e6bc44fba398b4a1cbd24d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/emiliomarinone/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-a86504b77b685c7c.arrow\n",
      "Loading cached processed dataset at /Users/emiliomarinone/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-cb0c14d5a00f31f1.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4bd1888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34dabea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Despair and Anger in Small Russian Town After Siege  BESLAN, Russia (Reuters) - The killing of more than 320  children, parents and teachers during the bloody end to a  53-hour school siege left barely a family untouched in the  small Russian town of Beslan.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  13905,\n",
       "  1998,\n",
       "  4963,\n",
       "  1999,\n",
       "  2235,\n",
       "  2845,\n",
       "  2237,\n",
       "  2044,\n",
       "  6859,\n",
       "  2022,\n",
       "  14540,\n",
       "  2319,\n",
       "  1010,\n",
       "  3607,\n",
       "  1006,\n",
       "  26665,\n",
       "  1007,\n",
       "  1011,\n",
       "  1996,\n",
       "  4288,\n",
       "  1997,\n",
       "  2062,\n",
       "  2084,\n",
       "  13710,\n",
       "  2336,\n",
       "  1010,\n",
       "  3008,\n",
       "  1998,\n",
       "  5089,\n",
       "  2076,\n",
       "  1996,\n",
       "  6703,\n",
       "  2203,\n",
       "  2000,\n",
       "  1037,\n",
       "  5187,\n",
       "  1011,\n",
       "  3178,\n",
       "  2082,\n",
       "  6859,\n",
       "  2187,\n",
       "  4510,\n",
       "  1037,\n",
       "  2155,\n",
       "  22154,\n",
       "  1999,\n",
       "  1996,\n",
       "  2235,\n",
       "  2845,\n",
       "  2237,\n",
       "  1997,\n",
       "  2022,\n",
       "  14540,\n",
       "  2319,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "080671fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2,\n",
       " 'input_ids': [101,\n",
       "  10069,\n",
       "  2005,\n",
       "  1056,\n",
       "  1050,\n",
       "  11550,\n",
       "  2044,\n",
       "  7566,\n",
       "  9209,\n",
       "  5052,\n",
       "  3667,\n",
       "  2012,\n",
       "  6769,\n",
       "  2047,\n",
       "  8095,\n",
       "  2360,\n",
       "  2027,\n",
       "  2024,\n",
       "  1005,\n",
       "  9364,\n",
       "  1005,\n",
       "  2044,\n",
       "  7566,\n",
       "  2007,\n",
       "  16654,\n",
       "  6687,\n",
       "  3813,\n",
       "  2976,\n",
       "  9587,\n",
       "  24848,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c549111",
   "metadata": {},
   "source": [
    "## Define metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9f77855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ea200988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(len(labels),len(labels)))\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    display.plot(cmap=\"Greens\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(cm)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a0108f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1]*50 + [0]*50\n",
    "y_pred = [1]*40 + [0]*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b14ca5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0. ]\n",
      " [0.2 0.8]]\n"
     ]
    }
   ],
   "source": [
    "cm = plot_confusion_matrix(y_true, y_pred, labels=[\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "70b6f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.83333333, 1.        ]),\n",
       " array([1. , 0.8]),\n",
       " array([0.90909091, 0.88888889]),\n",
       " array([50, 50]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0c1b5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prfs(y_true, y_pred, labels):\n",
    "    # fig, ax = plt.subplots(figsize=(4, len(labels)))\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = fig.add_subplot(111, frameon=True, xticks=[], yticks=[])\n",
    "\n",
    "    prfs = precision_recall_fscore_support(y_true, y_pred)\n",
    "    plt.table(\n",
    "        cellText=prfs,\n",
    "        rowLabels=[\"Precision\", \"Recall\", \"F1\", \"Support\"],\n",
    "        cellLoc=\"left\",\n",
    "        colLabels=labels,\n",
    "        colWidths = [.3]*len(prfs[0]),\n",
    "        loc=\"center\",\n",
    "        cellColours=plt.cm.hot(prfs),\n",
    "        bbox=None\n",
    "    )\n",
    "    # display.plot(cmap=\"Greens\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Precision, recall, f1 score, true labels per class\")\n",
    "    plt.show()\n",
    "    return prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "242aeb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prfs = plot_prfs(y_true, y_pred, labels=[\"1\", \"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e60d9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training loop\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    return {\"f1\": f1_score(labels, preds, average=\"weighted\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f08b6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e30e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6325177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/emiliomarinone/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/emiliomarinone/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d1ea1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/emiliomarinone/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"World\",\n",
      "    \"1\": \"Sports\",\n",
      "    \"2\": \"Business\",\n",
      "    \"3\": \"Sci/Tech\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Business\": 2,\n",
      "    \"Sci/Tech\": 3,\n",
      "    \"Sports\": 1,\n",
      "    \"World\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/emiliomarinone/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    label2id=encoded_intents,\n",
    "    id2label=inverse_encoded_intents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bbd130fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4eb8db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "80ef7332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['bert.embeddings.position_ids', 'bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8415257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "for key, values in state_dict.items():\n",
    "    print(values.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ae0813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "maxs = []\n",
    "mins = []\n",
    "\n",
    "keys_split = OrderedDict()\n",
    "for key, value in state_dict.items():\n",
    "    key_dot_split = key.split(\".\")\n",
    "    if key_dot_split[1] == \"embeddings\":\n",
    "        split_key = \"embeddings\"\n",
    "    \n",
    "    elif key_dot_split[1] == \"encoder\":\n",
    "        # eg: key == \"bert.encoder.layer.0.attention.self.query.weight\"\n",
    "        # ->: split_key == \"econder_layer_0\"\n",
    "        split_key = \"_\".join(key_dot_split[1:4])\n",
    "    \n",
    "    elif key_dot_split[1] == \"pooler\":\n",
    "        split_key = \"pooler\"\n",
    "    \n",
    "    elif key_dot_split[0] == \"classifier\":\n",
    "        split_key = \"classifier\"\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected key: {key}\")\n",
    "    \n",
    "    value = value.to(torch.float)\n",
    "    # here value from 0 to embedding dim - 1 \n",
    "    if key.endswith(\"position_ids\"):\n",
    "        mean = 0\n",
    "        std = 0\n",
    "        max_ = 0\n",
    "        min_ = 0\n",
    "    else:\n",
    "        mean = torch.mean(torch.flatten(value))\n",
    "        std = torch.std(value)\n",
    "        max_ = torch.max(value)\n",
    "        min_ = torch.min(value)\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "        maxs.append(max_)\n",
    "        mins.append(min_)\n",
    "        \n",
    "    tuple_ = (key, value.shape, max_, min_, mean, std)\n",
    "    try:\n",
    "        keys_split[split_key].append(tuple_)\n",
    "        \n",
    "    except KeyError:\n",
    "        keys_split[split_key] = [tuple_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d38ed0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings\n",
      "[('bert.embeddings.position_ids', torch.Size([1, 512]), 0, 0, 0, 0),\n",
      " ('bert.embeddings.word_embeddings.weight',\n",
      "  torch.Size([30522, 768]),\n",
      "  tensor(0.8729),\n",
      "  tensor(-0.9504),\n",
      "  tensor(-0.0280),\n",
      "  tensor(0.0427)),\n",
      " ('bert.embeddings.position_embeddings.weight',\n",
      "  torch.Size([512, 768]),\n",
      "  tensor(0.7269),\n",
      "  tensor(-0.9487),\n",
      "  tensor(-3.8740e-05),\n",
      "  tensor(0.0161)),\n",
      " ('bert.embeddings.token_type_embeddings.weight',\n",
      "  torch.Size([2, 768]),\n",
      "  tensor(0.2973),\n",
      "  tensor(-0.6952),\n",
      "  tensor(-0.0009),\n",
      "  tensor(0.0336)),\n",
      " ('bert.embeddings.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9831),\n",
      "  tensor(0.0893),\n",
      "  tensor(0.8493),\n",
      "  tensor(0.1340)),\n",
      " ('bert.embeddings.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.8021),\n",
      "  tensor(-0.5555),\n",
      "  tensor(-0.0196),\n",
      "  tensor(0.0693))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_0\n",
      "[('bert.encoder.layer.0.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.4541),\n",
      "  tensor(-0.5249),\n",
      "  tensor(3.5584e-05),\n",
      "  tensor(0.0431)),\n",
      " ('bert.encoder.layer.0.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.8620),\n",
      "  tensor(-1.0507),\n",
      "  tensor(0.0063),\n",
      "  tensor(0.2809)),\n",
      " ('bert.encoder.layer.0.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.8335),\n",
      "  tensor(-0.7098),\n",
      "  tensor(4.9594e-06),\n",
      "  tensor(0.0428)),\n",
      " ('bert.encoder.layer.0.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0106),\n",
      "  tensor(-0.0124),\n",
      "  tensor(-0.0003),\n",
      "  tensor(0.0032)),\n",
      " ('bert.encoder.layer.0.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1932),\n",
      "  tensor(-0.1644),\n",
      "  tensor(-3.3003e-05),\n",
      "  tensor(0.0288)),\n",
      " ('bert.encoder.layer.0.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2503),\n",
      "  tensor(-0.1789),\n",
      "  tensor(0.0018),\n",
      "  tensor(0.0407)),\n",
      " ('bert.encoder.layer.0.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.5870),\n",
      "  tensor(-0.4947),\n",
      "  tensor(-2.0736e-05),\n",
      "  tensor(0.0286)),\n",
      " ('bert.encoder.layer.0.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1477),\n",
      "  tensor(-0.3073),\n",
      "  tensor(-0.0011),\n",
      "  tensor(0.0355)),\n",
      " ('bert.encoder.layer.0.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(2.9968),\n",
      "  tensor(0.7153),\n",
      "  tensor(0.9585),\n",
      "  tensor(0.0835)),\n",
      " ('bert.encoder.layer.0.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.8336),\n",
      "  tensor(-4.2050),\n",
      "  tensor(-0.0182),\n",
      "  tensor(0.3292)),\n",
      " ('bert.encoder.layer.0.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.3222),\n",
      "  tensor(-0.2978),\n",
      "  tensor(-3.0439e-05),\n",
      "  tensor(0.0374)),\n",
      " ('bert.encoder.layer.0.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.4057),\n",
      "  tensor(-0.3515),\n",
      "  tensor(-0.1081),\n",
      "  tensor(0.0494)),\n",
      " ('bert.encoder.layer.0.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(0.7699),\n",
      "  tensor(-1.6791),\n",
      "  tensor(-8.5034e-05),\n",
      "  tensor(0.0358)),\n",
      " ('bert.encoder.layer.0.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.3393),\n",
      "  tensor(-0.5256),\n",
      "  tensor(-0.0021),\n",
      "  tensor(0.0802)),\n",
      " ('bert.encoder.layer.0.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.8120),\n",
      "  tensor(0.1001),\n",
      "  tensor(0.7559),\n",
      "  tensor(0.0563)),\n",
      " ('bert.encoder.layer.0.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4190),\n",
      "  tensor(-1.3253),\n",
      "  tensor(-0.0366),\n",
      "  tensor(0.0985))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_1\n",
      "[('bert.encoder.layer.1.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3042),\n",
      "  tensor(-0.3894),\n",
      "  tensor(-0.0003),\n",
      "  tensor(0.0425)),\n",
      " ('bert.encoder.layer.1.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.8882),\n",
      "  tensor(-0.8810),\n",
      "  tensor(0.0158),\n",
      "  tensor(0.1807)),\n",
      " ('bert.encoder.layer.1.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3609),\n",
      "  tensor(-0.3605),\n",
      "  tensor(2.7258e-05),\n",
      "  tensor(0.0425)),\n",
      " ('bert.encoder.layer.1.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0221),\n",
      "  tensor(-0.0280),\n",
      "  tensor(6.3875e-05),\n",
      "  tensor(0.0051)),\n",
      " ('bert.encoder.layer.1.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1927),\n",
      "  tensor(-0.2130),\n",
      "  tensor(7.1436e-06),\n",
      "  tensor(0.0284)),\n",
      " ('bert.encoder.layer.1.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2519),\n",
      "  tensor(-0.4813),\n",
      "  tensor(1.5100e-05),\n",
      "  tensor(0.0419)),\n",
      " ('bert.encoder.layer.1.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3610),\n",
      "  tensor(-0.3103),\n",
      "  tensor(2.9250e-05),\n",
      "  tensor(0.0280)),\n",
      " ('bert.encoder.layer.1.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2376),\n",
      "  tensor(-0.2888),\n",
      "  tensor(-0.0016),\n",
      "  tensor(0.0604)),\n",
      " ('bert.encoder.layer.1.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.0383),\n",
      "  tensor(0.6566),\n",
      "  tensor(0.8757),\n",
      "  tensor(0.0878)),\n",
      " ('bert.encoder.layer.1.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.5439),\n",
      "  tensor(-2.4629),\n",
      "  tensor(-0.0178),\n",
      "  tensor(0.1936)),\n",
      " ('bert.encoder.layer.1.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.5060),\n",
      "  tensor(-0.3096),\n",
      "  tensor(9.1771e-05),\n",
      "  tensor(0.0392)),\n",
      " ('bert.encoder.layer.1.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.6664),\n",
      "  tensor(-0.3129),\n",
      "  tensor(-0.0931),\n",
      "  tensor(0.0612)),\n",
      " ('bert.encoder.layer.1.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(1.1918),\n",
      "  tensor(-2.1522),\n",
      "  tensor(-5.7430e-05),\n",
      "  tensor(0.0379)),\n",
      " ('bert.encoder.layer.1.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2654),\n",
      "  tensor(-0.3056),\n",
      "  tensor(-0.0015),\n",
      "  tensor(0.0606)),\n",
      " ('bert.encoder.layer.1.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9688),\n",
      "  tensor(0.2779),\n",
      "  tensor(0.8695),\n",
      "  tensor(0.0690)),\n",
      " ('bert.encoder.layer.1.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4060),\n",
      "  tensor(-0.6779),\n",
      "  tensor(-0.0335),\n",
      "  tensor(0.0863))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_2\n",
      "[('bert.encoder.layer.2.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.5181),\n",
      "  tensor(-0.5283),\n",
      "  tensor(4.4332e-05),\n",
      "  tensor(0.0477)),\n",
      " ('bert.encoder.layer.2.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.5045),\n",
      "  tensor(-0.8219),\n",
      "  tensor(0.0005),\n",
      "  tensor(0.1296)),\n",
      " ('bert.encoder.layer.2.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.4602),\n",
      "  tensor(-0.4553),\n",
      "  tensor(3.7601e-05),\n",
      "  tensor(0.0467)),\n",
      " ('bert.encoder.layer.2.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0271),\n",
      "  tensor(-0.0160),\n",
      "  tensor(-3.0301e-05),\n",
      "  tensor(0.0042)),\n",
      " ('bert.encoder.layer.2.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2070),\n",
      "  tensor(-0.1893),\n",
      "  tensor(-5.0980e-05),\n",
      "  tensor(0.0279)),\n",
      " ('bert.encoder.layer.2.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6010),\n",
      "  tensor(-0.2820),\n",
      "  tensor(0.0038),\n",
      "  tensor(0.0576)),\n",
      " ('bert.encoder.layer.2.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2444),\n",
      "  tensor(-0.2687),\n",
      "  tensor(-2.5350e-06),\n",
      "  tensor(0.0271)),\n",
      " ('bert.encoder.layer.2.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4130),\n",
      "  tensor(-0.4169),\n",
      "  tensor(-0.0011),\n",
      "  tensor(0.0895)),\n",
      " ('bert.encoder.layer.2.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(2.2833),\n",
      "  tensor(0.5520),\n",
      "  tensor(0.8675),\n",
      "  tensor(0.0740)),\n",
      " ('bert.encoder.layer.2.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6736),\n",
      "  tensor(-2.0185),\n",
      "  tensor(-0.0154),\n",
      "  tensor(0.1760)),\n",
      " ('bert.encoder.layer.2.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.5734),\n",
      "  tensor(-0.6285),\n",
      "  tensor(7.5297e-05),\n",
      "  tensor(0.0399)),\n",
      " ('bert.encoder.layer.2.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.6128),\n",
      "  tensor(-0.3586),\n",
      "  tensor(-0.0964),\n",
      "  tensor(0.0639)),\n",
      " ('bert.encoder.layer.2.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(1.0375),\n",
      "  tensor(-3.3303),\n",
      "  tensor(-3.9511e-05),\n",
      "  tensor(0.0383)),\n",
      " ('bert.encoder.layer.2.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2442),\n",
      "  tensor(-0.3674),\n",
      "  tensor(-0.0014),\n",
      "  tensor(0.0716)),\n",
      " ('bert.encoder.layer.2.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9435),\n",
      "  tensor(0.4084),\n",
      "  tensor(0.8513),\n",
      "  tensor(0.0524)),\n",
      " ('bert.encoder.layer.2.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2303),\n",
      "  tensor(-0.2981),\n",
      "  tensor(-0.0310),\n",
      "  tensor(0.0748))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_3\n",
      "[('bert.encoder.layer.3.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3334),\n",
      "  tensor(-0.3360),\n",
      "  tensor(0.0003),\n",
      "  tensor(0.0430)),\n",
      " ('bert.encoder.layer.3.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.5715),\n",
      "  tensor(-0.7681),\n",
      "  tensor(-0.0113),\n",
      "  tensor(0.1374)),\n",
      " ('bert.encoder.layer.3.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3454),\n",
      "  tensor(-0.3447),\n",
      "  tensor(1.5101e-05),\n",
      "  tensor(0.0428)),\n",
      " ('bert.encoder.layer.3.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0215),\n",
      "  tensor(-0.0219),\n",
      "  tensor(-0.0002),\n",
      "  tensor(0.0048)),\n",
      " ('bert.encoder.layer.3.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1913),\n",
      "  tensor(-0.1825),\n",
      "  tensor(-6.7477e-05),\n",
      "  tensor(0.0312)),\n",
      " ('bert.encoder.layer.3.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.3208),\n",
      "  tensor(-0.2598),\n",
      "  tensor(0.0012),\n",
      "  tensor(0.0327)),\n",
      " ('bert.encoder.layer.3.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2648),\n",
      "  tensor(-0.3878),\n",
      "  tensor(7.1364e-06),\n",
      "  tensor(0.0291)),\n",
      " ('bert.encoder.layer.3.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2786),\n",
      "  tensor(-0.2284),\n",
      "  tensor(-0.0006),\n",
      "  tensor(0.0720)),\n",
      " ('bert.encoder.layer.3.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.4967),\n",
      "  tensor(0.5558),\n",
      "  tensor(0.8627),\n",
      "  tensor(0.1184)),\n",
      " ('bert.encoder.layer.3.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6471),\n",
      "  tensor(-1.5130),\n",
      "  tensor(-0.0111),\n",
      "  tensor(0.1596)),\n",
      " ('bert.encoder.layer.3.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.6304),\n",
      "  tensor(-0.6577),\n",
      "  tensor(-7.1698e-05),\n",
      "  tensor(0.0405)),\n",
      " ('bert.encoder.layer.3.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.5937),\n",
      "  tensor(-0.3895),\n",
      "  tensor(-0.0973),\n",
      "  tensor(0.0564)),\n",
      " ('bert.encoder.layer.3.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(0.7792),\n",
      "  tensor(-6.6404),\n",
      "  tensor(-3.5986e-05),\n",
      "  tensor(0.0393)),\n",
      " ('bert.encoder.layer.3.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2060),\n",
      "  tensor(-0.6084),\n",
      "  tensor(-0.0017),\n",
      "  tensor(0.0732)),\n",
      " ('bert.encoder.layer.3.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9094),\n",
      "  tensor(0.3881),\n",
      "  tensor(0.8111),\n",
      "  tensor(0.0438)),\n",
      " ('bert.encoder.layer.3.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1747),\n",
      "  tensor(-0.2571),\n",
      "  tensor(-0.0332),\n",
      "  tensor(0.0523))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_4\n",
      "[('bert.encoder.layer.4.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3500),\n",
      "  tensor(-0.3893),\n",
      "  tensor(-0.0001),\n",
      "  tensor(0.0421)),\n",
      " ('bert.encoder.layer.4.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6234),\n",
      "  tensor(-0.7207),\n",
      "  tensor(0.0023),\n",
      "  tensor(0.1478)),\n",
      " ('bert.encoder.layer.4.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3910),\n",
      "  tensor(-0.3663),\n",
      "  tensor(1.2568e-05),\n",
      "  tensor(0.0418)),\n",
      " ('bert.encoder.layer.4.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0221),\n",
      "  tensor(-0.0175),\n",
      "  tensor(0.0001),\n",
      "  tensor(0.0048)),\n",
      " ('bert.encoder.layer.4.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2093),\n",
      "  tensor(-0.2089),\n",
      "  tensor(5.9833e-05),\n",
      "  tensor(0.0349)),\n",
      " ('bert.encoder.layer.4.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1672),\n",
      "  tensor(-0.1599),\n",
      "  tensor(-0.0004),\n",
      "  tensor(0.0268)),\n",
      " ('bert.encoder.layer.4.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2368),\n",
      "  tensor(-0.3289),\n",
      "  tensor(1.5334e-05),\n",
      "  tensor(0.0325)),\n",
      " ('bert.encoder.layer.4.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.5205),\n",
      "  tensor(-0.1432),\n",
      "  tensor(-8.3270e-05),\n",
      "  tensor(0.0416)),\n",
      " ('bert.encoder.layer.4.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.7374),\n",
      "  tensor(0.5653),\n",
      "  tensor(0.8387),\n",
      "  tensor(0.1238)),\n",
      " ('bert.encoder.layer.4.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7243),\n",
      "  tensor(-1.2970),\n",
      "  tensor(-0.0182),\n",
      "  tensor(0.1442)),\n",
      " ('bert.encoder.layer.4.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.8644),\n",
      "  tensor(-0.5355),\n",
      "  tensor(8.5384e-05),\n",
      "  tensor(0.0408)),\n",
      " ('bert.encoder.layer.4.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.5084),\n",
      "  tensor(-0.4079),\n",
      "  tensor(-0.0971),\n",
      "  tensor(0.0713)),\n",
      " ('bert.encoder.layer.4.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(1.9449),\n",
      "  tensor(-6.8176),\n",
      "  tensor(-1.6501e-05),\n",
      "  tensor(0.0399)),\n",
      " ('bert.encoder.layer.4.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2072),\n",
      "  tensor(-0.3430),\n",
      "  tensor(-0.0010),\n",
      "  tensor(0.0540)),\n",
      " ('bert.encoder.layer.4.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9394),\n",
      "  tensor(0.3605),\n",
      "  tensor(0.8397),\n",
      "  tensor(0.0445)),\n",
      " ('bert.encoder.layer.4.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2101),\n",
      "  tensor(-0.2489),\n",
      "  tensor(-0.0312),\n",
      "  tensor(0.0508))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_5\n",
      "[('bert.encoder.layer.5.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3671),\n",
      "  tensor(-0.3402),\n",
      "  tensor(-2.6863e-05),\n",
      "  tensor(0.0434)),\n",
      " ('bert.encoder.layer.5.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6927),\n",
      "  tensor(-0.5518),\n",
      "  tensor(-0.0014),\n",
      "  tensor(0.1261)),\n",
      " ('bert.encoder.layer.5.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3595),\n",
      "  tensor(-0.3216),\n",
      "  tensor(-5.9039e-05),\n",
      "  tensor(0.0433)),\n",
      " ('bert.encoder.layer.5.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0236),\n",
      "  tensor(-0.0187),\n",
      "  tensor(0.0001),\n",
      "  tensor(0.0060)),\n",
      " ('bert.encoder.layer.5.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2137),\n",
      "  tensor(-0.2209),\n",
      "  tensor(-3.8215e-05),\n",
      "  tensor(0.0349)),\n",
      " ('bert.encoder.layer.5.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0991),\n",
      "  tensor(-0.1973),\n",
      "  tensor(0.0003),\n",
      "  tensor(0.0274)),\n",
      " ('bert.encoder.layer.5.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3216),\n",
      "  tensor(-0.2976),\n",
      "  tensor(1.6166e-05),\n",
      "  tensor(0.0332)),\n",
      " ('bert.encoder.layer.5.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7710),\n",
      "  tensor(-0.1153),\n",
      "  tensor(7.4998e-06),\n",
      "  tensor(0.0437)),\n",
      " ('bert.encoder.layer.5.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.3955),\n",
      "  tensor(0.6132),\n",
      "  tensor(0.8466),\n",
      "  tensor(0.1108)),\n",
      " ('bert.encoder.layer.5.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6274),\n",
      "  tensor(-1.3960),\n",
      "  tensor(-0.0183),\n",
      "  tensor(0.1366)),\n",
      " ('bert.encoder.layer.5.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.5516),\n",
      "  tensor(-0.3540),\n",
      "  tensor(4.6656e-05),\n",
      "  tensor(0.0405)),\n",
      " ('bert.encoder.layer.5.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.5898),\n",
      "  tensor(-0.4363),\n",
      "  tensor(-0.0981),\n",
      "  tensor(0.0726)),\n",
      " ('bert.encoder.layer.5.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(2.4973),\n",
      "  tensor(-6.0235),\n",
      "  tensor(5.8152e-06),\n",
      "  tensor(0.0393)),\n",
      " ('bert.encoder.layer.5.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1940),\n",
      "  tensor(-0.6168),\n",
      "  tensor(-0.0003),\n",
      "  tensor(0.0578)),\n",
      " ('bert.encoder.layer.5.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9391),\n",
      "  tensor(0.4106),\n",
      "  tensor(0.8322),\n",
      "  tensor(0.0370)),\n",
      " ('bert.encoder.layer.5.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4026),\n",
      "  tensor(-0.3944),\n",
      "  tensor(-0.0318),\n",
      "  tensor(0.0596))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_6\n",
      "[('bert.encoder.layer.6.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3203),\n",
      "  tensor(-0.2717),\n",
      "  tensor(6.3665e-05),\n",
      "  tensor(0.0430)),\n",
      " ('bert.encoder.layer.6.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.5922),\n",
      "  tensor(-0.6010),\n",
      "  tensor(-0.0054),\n",
      "  tensor(0.1281)),\n",
      " ('bert.encoder.layer.6.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3601),\n",
      "  tensor(-0.3337),\n",
      "  tensor(-5.1652e-05),\n",
      "  tensor(0.0430)),\n",
      " ('bert.encoder.layer.6.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0216),\n",
      "  tensor(-0.0231),\n",
      "  tensor(-0.0001),\n",
      "  tensor(0.0053)),\n",
      " ('bert.encoder.layer.6.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1851),\n",
      "  tensor(-0.1938),\n",
      "  tensor(2.3585e-05),\n",
      "  tensor(0.0340)),\n",
      " ('bert.encoder.layer.6.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1582),\n",
      "  tensor(-0.1569),\n",
      "  tensor(0.0004),\n",
      "  tensor(0.0353)),\n",
      " ('bert.encoder.layer.6.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2004),\n",
      "  tensor(-0.2160),\n",
      "  tensor(-2.8769e-06),\n",
      "  tensor(0.0322)),\n",
      " ('bert.encoder.layer.6.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.8215),\n",
      "  tensor(-0.2016),\n",
      "  tensor(5.9110e-05),\n",
      "  tensor(0.0505)),\n",
      " ('bert.encoder.layer.6.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.3445),\n",
      "  tensor(0.6245),\n",
      "  tensor(0.8275),\n",
      "  tensor(0.1081)),\n",
      " ('bert.encoder.layer.6.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6334),\n",
      "  tensor(-2.0029),\n",
      "  tensor(-0.0190),\n",
      "  tensor(0.1411)),\n",
      " ('bert.encoder.layer.6.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.3509),\n",
      "  tensor(-0.2982),\n",
      "  tensor(-3.4460e-06),\n",
      "  tensor(0.0408)),\n",
      " ('bert.encoder.layer.6.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.7195),\n",
      "  tensor(-0.4642),\n",
      "  tensor(-0.0955),\n",
      "  tensor(0.0725)),\n",
      " ('bert.encoder.layer.6.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(1.6329),\n",
      "  tensor(-4.8092),\n",
      "  tensor(1.5482e-05),\n",
      "  tensor(0.0388)),\n",
      " ('bert.encoder.layer.6.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2434),\n",
      "  tensor(-0.5503),\n",
      "  tensor(-0.0002),\n",
      "  tensor(0.0702)),\n",
      " ('bert.encoder.layer.6.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9152),\n",
      "  tensor(0.3747),\n",
      "  tensor(0.8336),\n",
      "  tensor(0.0365)),\n",
      " ('bert.encoder.layer.6.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7849),\n",
      "  tensor(-0.3370),\n",
      "  tensor(-0.0332),\n",
      "  tensor(0.0634))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_7\n",
      "[('bert.encoder.layer.7.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3302),\n",
      "  tensor(-0.2687),\n",
      "  tensor(-5.8056e-06),\n",
      "  tensor(0.0434)),\n",
      " ('bert.encoder.layer.7.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.5888),\n",
      "  tensor(-0.8655),\n",
      "  tensor(-0.0035),\n",
      "  tensor(0.1451)),\n",
      " ('bert.encoder.layer.7.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.4343),\n",
      "  tensor(-0.3855),\n",
      "  tensor(-1.1958e-05),\n",
      "  tensor(0.0435)),\n",
      " ('bert.encoder.layer.7.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0203),\n",
      "  tensor(-0.0214),\n",
      "  tensor(0.0001),\n",
      "  tensor(0.0054)),\n",
      " ('bert.encoder.layer.7.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1689),\n",
      "  tensor(-0.1949),\n",
      "  tensor(9.5293e-05),\n",
      "  tensor(0.0329)),\n",
      " ('bert.encoder.layer.7.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1878),\n",
      "  tensor(-0.2363),\n",
      "  tensor(-0.0023),\n",
      "  tensor(0.0413)),\n",
      " ('bert.encoder.layer.7.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2465),\n",
      "  tensor(-0.2450),\n",
      "  tensor(-1.4655e-05),\n",
      "  tensor(0.0317)),\n",
      " ('bert.encoder.layer.7.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.3827),\n",
      "  tensor(-0.1270),\n",
      "  tensor(0.0006),\n",
      "  tensor(0.0628)),\n",
      " ('bert.encoder.layer.7.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.3634),\n",
      "  tensor(0.6464),\n",
      "  tensor(0.8221),\n",
      "  tensor(0.1059)),\n",
      " ('bert.encoder.layer.7.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4385),\n",
      "  tensor(-2.0484),\n",
      "  tensor(-0.0255),\n",
      "  tensor(0.1440)),\n",
      " ('bert.encoder.layer.7.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.3976),\n",
      "  tensor(-0.3186),\n",
      "  tensor(0.0003),\n",
      "  tensor(0.0391)),\n",
      " ('bert.encoder.layer.7.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.5762),\n",
      "  tensor(-0.4720),\n",
      "  tensor(-0.1021),\n",
      "  tensor(0.0624)),\n",
      " ('bert.encoder.layer.7.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(0.9514),\n",
      "  tensor(-3.5620),\n",
      "  tensor(5.4478e-07),\n",
      "  tensor(0.0375)),\n",
      " ('bert.encoder.layer.7.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2095),\n",
      "  tensor(-0.7445),\n",
      "  tensor(-0.0003),\n",
      "  tensor(0.0816)),\n",
      " ('bert.encoder.layer.7.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.1629),\n",
      "  tensor(0.3350),\n",
      "  tensor(0.8105),\n",
      "  tensor(0.0301)),\n",
      " ('bert.encoder.layer.7.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.9590),\n",
      "  tensor(-0.2165),\n",
      "  tensor(-0.0330),\n",
      "  tensor(0.0649))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bert.encoder.layer.8.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3501),\n",
      "  tensor(-0.3796),\n",
      "  tensor(0.0001),\n",
      "  tensor(0.0440)),\n",
      " ('bert.encoder.layer.8.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7405),\n",
      "  tensor(-0.6898),\n",
      "  tensor(-0.0089),\n",
      "  tensor(0.1745)),\n",
      " ('bert.encoder.layer.8.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3841),\n",
      "  tensor(-0.4017),\n",
      "  tensor(-4.2690e-05),\n",
      "  tensor(0.0441)),\n",
      " ('bert.encoder.layer.8.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0253),\n",
      "  tensor(-0.0181),\n",
      "  tensor(0.0002),\n",
      "  tensor(0.0067)),\n",
      " ('bert.encoder.layer.8.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1778),\n",
      "  tensor(-0.1872),\n",
      "  tensor(9.5409e-06),\n",
      "  tensor(0.0354)),\n",
      " ('bert.encoder.layer.8.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2395),\n",
      "  tensor(-0.4492),\n",
      "  tensor(-0.0006),\n",
      "  tensor(0.0443)),\n",
      " ('bert.encoder.layer.8.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.4107),\n",
      "  tensor(-0.5421),\n",
      "  tensor(-1.6891e-06),\n",
      "  tensor(0.0336)),\n",
      " ('bert.encoder.layer.8.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.2157),\n",
      "  tensor(-0.1956),\n",
      "  tensor(0.0003),\n",
      "  tensor(0.0639)),\n",
      " ('bert.encoder.layer.8.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.4025),\n",
      "  tensor(0.6144),\n",
      "  tensor(0.8368),\n",
      "  tensor(0.1031)),\n",
      " ('bert.encoder.layer.8.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.3632),\n",
      "  tensor(-1.7460),\n",
      "  tensor(-0.0267),\n",
      "  tensor(0.1277)),\n",
      " ('bert.encoder.layer.8.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.3764),\n",
      "  tensor(-0.4337),\n",
      "  tensor(0.0004),\n",
      "  tensor(0.0390)),\n",
      " ('bert.encoder.layer.8.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.4455),\n",
      "  tensor(-0.4334),\n",
      "  tensor(-0.0997),\n",
      "  tensor(0.0484)),\n",
      " ('bert.encoder.layer.8.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(1.1222),\n",
      "  tensor(-3.1352),\n",
      "  tensor(-3.6737e-07),\n",
      "  tensor(0.0373)),\n",
      " ('bert.encoder.layer.8.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4328),\n",
      "  tensor(-0.8095),\n",
      "  tensor(-6.3032e-05),\n",
      "  tensor(0.0867)),\n",
      " ('bert.encoder.layer.8.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.6179),\n",
      "  tensor(0.2616),\n",
      "  tensor(0.8311),\n",
      "  tensor(0.0422)),\n",
      " ('bert.encoder.layer.8.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6952),\n",
      "  tensor(-0.2501),\n",
      "  tensor(-0.0350),\n",
      "  tensor(0.0616))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_9\n",
      "[('bert.encoder.layer.9.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2692),\n",
      "  tensor(-0.2449),\n",
      "  tensor(-0.0001),\n",
      "  tensor(0.0459)),\n",
      " ('bert.encoder.layer.9.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7653),\n",
      "  tensor(-0.7548),\n",
      "  tensor(0.0061),\n",
      "  tensor(0.1918)),\n",
      " ('bert.encoder.layer.9.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.6270),\n",
      "  tensor(-0.5265),\n",
      "  tensor(1.9486e-05),\n",
      "  tensor(0.0459)),\n",
      " ('bert.encoder.layer.9.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0323),\n",
      "  tensor(-0.0248),\n",
      "  tensor(9.7660e-05),\n",
      "  tensor(0.0066)),\n",
      " ('bert.encoder.layer.9.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2093),\n",
      "  tensor(-0.1981),\n",
      "  tensor(2.8408e-05),\n",
      "  tensor(0.0345)),\n",
      " ('bert.encoder.layer.9.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2559),\n",
      "  tensor(-0.2396),\n",
      "  tensor(-0.0008),\n",
      "  tensor(0.0380)),\n",
      " ('bert.encoder.layer.9.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3581),\n",
      "  tensor(-0.3737),\n",
      "  tensor(1.0377e-05),\n",
      "  tensor(0.0327)),\n",
      " ('bert.encoder.layer.9.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.6455),\n",
      "  tensor(-0.1621),\n",
      "  tensor(0.0004),\n",
      "  tensor(0.0615)),\n",
      " ('bert.encoder.layer.9.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(2.5250),\n",
      "  tensor(0.6058),\n",
      "  tensor(0.8172),\n",
      "  tensor(0.0807)),\n",
      " ('bert.encoder.layer.9.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.0449),\n",
      "  tensor(-1.4833),\n",
      "  tensor(-0.0297),\n",
      "  tensor(0.1332)),\n",
      " ('bert.encoder.layer.9.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.7370),\n",
      "  tensor(-0.8228),\n",
      "  tensor(0.0005),\n",
      "  tensor(0.0397)),\n",
      " ('bert.encoder.layer.9.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.5708),\n",
      "  tensor(-0.3638),\n",
      "  tensor(-0.1046),\n",
      "  tensor(0.0472)),\n",
      " ('bert.encoder.layer.9.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(2.1869),\n",
      "  tensor(-3.0746),\n",
      "  tensor(-1.0401e-05),\n",
      "  tensor(0.0390)),\n",
      " ('bert.encoder.layer.9.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.3462),\n",
      "  tensor(-0.6382),\n",
      "  tensor(-0.0006),\n",
      "  tensor(0.0801)),\n",
      " ('bert.encoder.layer.9.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.4368),\n",
      "  tensor(0.1384),\n",
      "  tensor(0.8005),\n",
      "  tensor(0.0604)),\n",
      " ('bert.encoder.layer.9.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.4343),\n",
      "  tensor(-0.4158),\n",
      "  tensor(-0.0322),\n",
      "  tensor(0.0569))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_10\n",
      "[('bert.encoder.layer.10.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.4639),\n",
      "  tensor(-0.4197),\n",
      "  tensor(0.0002),\n",
      "  tensor(0.0460)),\n",
      " ('bert.encoder.layer.10.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.0763),\n",
      "  tensor(-0.9731),\n",
      "  tensor(-0.0104),\n",
      "  tensor(0.2300)),\n",
      " ('bert.encoder.layer.10.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2612),\n",
      "  tensor(-0.3221),\n",
      "  tensor(-1.8148e-05),\n",
      "  tensor(0.0457)),\n",
      " ('bert.encoder.layer.10.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0235),\n",
      "  tensor(-0.0220),\n",
      "  tensor(-5.6828e-05),\n",
      "  tensor(0.0064)),\n",
      " ('bert.encoder.layer.10.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2529),\n",
      "  tensor(-0.2470),\n",
      "  tensor(-3.9745e-05),\n",
      "  tensor(0.0356)),\n",
      " ('bert.encoder.layer.10.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.3121),\n",
      "  tensor(-0.2050),\n",
      "  tensor(0.0010),\n",
      "  tensor(0.0282)),\n",
      " ('bert.encoder.layer.10.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2857),\n",
      "  tensor(-0.2611),\n",
      "  tensor(6.5908e-06),\n",
      "  tensor(0.0334)),\n",
      " ('bert.encoder.layer.10.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1652),\n",
      "  tensor(-0.1593),\n",
      "  tensor(0.0002),\n",
      "  tensor(0.0527)),\n",
      " ('bert.encoder.layer.10.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(3.1994),\n",
      "  tensor(0.5300),\n",
      "  tensor(0.8408),\n",
      "  tensor(0.1320)),\n",
      " ('bert.encoder.layer.10.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7659),\n",
      "  tensor(-1.8882),\n",
      "  tensor(-0.0206),\n",
      "  tensor(0.1301)),\n",
      " ('bert.encoder.layer.10.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(1.6366),\n",
      "  tensor(-1.6419),\n",
      "  tensor(3.7272e-05),\n",
      "  tensor(0.0389)),\n",
      " ('bert.encoder.layer.10.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.3873),\n",
      "  tensor(-0.3411),\n",
      "  tensor(-0.1042),\n",
      "  tensor(0.0384)),\n",
      " ('bert.encoder.layer.10.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(0.9038),\n",
      "  tensor(-6.3731),\n",
      "  tensor(-7.9907e-06),\n",
      "  tensor(0.0379)),\n",
      " ('bert.encoder.layer.10.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2845),\n",
      "  tensor(-1.1674),\n",
      "  tensor(-0.0006),\n",
      "  tensor(0.1026)),\n",
      " ('bert.encoder.layer.10.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.6714),\n",
      "  tensor(0.1450),\n",
      "  tensor(0.8173),\n",
      "  tensor(0.0618)),\n",
      " ('bert.encoder.layer.10.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.2342),\n",
      "  tensor(-0.6670),\n",
      "  tensor(-0.0403),\n",
      "  tensor(0.0682))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "encoder_layer_11\n",
      "[('bert.encoder.layer.11.attention.self.query.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.6601),\n",
      "  tensor(-0.7210),\n",
      "  tensor(-0.0001),\n",
      "  tensor(0.0455)),\n",
      " ('bert.encoder.layer.11.attention.self.query.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7960),\n",
      "  tensor(-0.8307),\n",
      "  tensor(0.0118),\n",
      "  tensor(0.2189)),\n",
      " ('bert.encoder.layer.11.attention.self.key.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3147),\n",
      "  tensor(-0.4733),\n",
      "  tensor(0.0002),\n",
      "  tensor(0.0445)),\n",
      " ('bert.encoder.layer.11.attention.self.key.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0332),\n",
      "  tensor(-0.0226),\n",
      "  tensor(-0.0002),\n",
      "  tensor(0.0053)),\n",
      " ('bert.encoder.layer.11.attention.self.value.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.2812),\n",
      "  tensor(-0.2622),\n",
      "  tensor(-2.2047e-05),\n",
      "  tensor(0.0392)),\n",
      " ('bert.encoder.layer.11.attention.self.value.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.0919),\n",
      "  tensor(-0.1244),\n",
      "  tensor(0.0004),\n",
      "  tensor(0.0203)),\n",
      " ('bert.encoder.layer.11.attention.output.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.1997),\n",
      "  tensor(-0.3128),\n",
      "  tensor(-3.3345e-06),\n",
      "  tensor(0.0368)),\n",
      " ('bert.encoder.layer.11.attention.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1376),\n",
      "  tensor(-0.1163),\n",
      "  tensor(-0.0002),\n",
      "  tensor(0.0378)),\n",
      " ('bert.encoder.layer.11.attention.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(1.6117),\n",
      "  tensor(0.6582),\n",
      "  tensor(0.8528),\n",
      "  tensor(0.0567)),\n",
      " ('bert.encoder.layer.11.attention.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.3322),\n",
      "  tensor(-2.2575),\n",
      "  tensor(-0.0367),\n",
      "  tensor(0.1078)),\n",
      " ('bert.encoder.layer.11.intermediate.dense.weight',\n",
      "  torch.Size([3072, 768]),\n",
      "  tensor(0.2824),\n",
      "  tensor(-0.4475),\n",
      "  tensor(0.0004),\n",
      "  tensor(0.0392)),\n",
      " ('bert.encoder.layer.11.intermediate.dense.bias',\n",
      "  torch.Size([3072]),\n",
      "  tensor(0.5641),\n",
      "  tensor(-0.4243),\n",
      "  tensor(-0.0762),\n",
      "  tensor(0.0534)),\n",
      " ('bert.encoder.layer.11.output.dense.weight',\n",
      "  torch.Size([768, 3072]),\n",
      "  tensor(0.9530),\n",
      "  tensor(-2.1484),\n",
      "  tensor(-6.7440e-06),\n",
      "  tensor(0.0358)),\n",
      " ('bert.encoder.layer.11.output.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1456),\n",
      "  tensor(-0.5731),\n",
      "  tensor(-0.0008),\n",
      "  tensor(0.0574)),\n",
      " ('bert.encoder.layer.11.output.LayerNorm.weight',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.7782),\n",
      "  tensor(0.2733),\n",
      "  tensor(0.6330),\n",
      "  tensor(0.0275)),\n",
      " ('bert.encoder.layer.11.output.LayerNorm.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.2251),\n",
      "  tensor(-0.1922),\n",
      "  tensor(-0.0192),\n",
      "  tensor(0.0495))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "pooler\n",
      "[('bert.pooler.dense.weight',\n",
      "  torch.Size([768, 768]),\n",
      "  tensor(0.3859),\n",
      "  tensor(-0.3935),\n",
      "  tensor(3.0755e-05),\n",
      "  tensor(0.0285)),\n",
      " ('bert.pooler.dense.bias',\n",
      "  torch.Size([768]),\n",
      "  tensor(0.1043),\n",
      "  tensor(-0.0966),\n",
      "  tensor(-0.0008),\n",
      "  tensor(0.0347))]\n",
      "\n",
      "==================================================\n",
      "\n",
      "classifier\n",
      "[('classifier.weight',\n",
      "  torch.Size([4, 768]),\n",
      "  tensor(0.0759),\n",
      "  tensor(-0.0776),\n",
      "  tensor(0.0002),\n",
      "  tensor(0.0201)),\n",
      " ('classifier.bias',\n",
      "  torch.Size([4]),\n",
      "  tensor(0.),\n",
      "  tensor(0.),\n",
      "  tensor(0.),\n",
      "  tensor(0.))]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_info_dict(obj):\n",
    "    for key, value in obj.items():\n",
    "        print(key)\n",
    "        pprint(value)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print_model_info_dict(keys_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c18e0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:  mean\n",
      "Mean:  tensor(0.0941)\n",
      "Std:  tensor(0.2802)\n",
      "Max:  tensor(0.9585)\n",
      "Min:  tensor(-0.1081)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Stats:  std\n",
      "Mean:  tensor(0.0619)\n",
      "Std:  tensor(0.0486)\n",
      "Max:  tensor(0.3292)\n",
      "Min:  tensor(0.)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Stats:  max\n",
      "Mean:  tensor(0.6727)\n",
      "Std:  tensor(0.7307)\n",
      "Max:  tensor(3.7374)\n",
      "Min:  tensor(0.)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Stats:  min\n",
      "Mean:  tensor(-0.6090)\n",
      "Std:  tensor(1.1549)\n",
      "Max:  tensor(0.7153)\n",
      "Min:  tensor(-6.8176)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def max_min_mean_std(obj, name=\"\"):\n",
    "    print(\"Stats: \", name)\n",
    "    print(\"Mean: \", torch.mean(torch.Tensor(obj)))\n",
    "    print(\"Std: \", torch.std(torch.Tensor(obj)))\n",
    "    print(\"Max: \", torch.max(torch.Tensor(obj)))\n",
    "    print(\"Min: \", torch.min(torch.Tensor(obj)))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# They exclude values from embedding_ids  [0,512)\n",
    "max_min_mean_std(means, name=\"mean\")\n",
    "max_min_mean_std(stds, name=\"std\")\n",
    "max_min_mean_std(maxs, name=\"max\")\n",
    "max_min_mean_std(mins, name=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8a088c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{model_id}-finetuned-{dataset_id}\"\n",
    "batch_size = 64\n",
    "logging_steps = dataset[\"train\"].num_rows // batch_size\n",
    "train_epochs = 1\n",
    "lr = 5e-4\n",
    "weight_decay=0.1\n",
    "eval_strategy=\"epoch\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=train_epochs,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    evaluation_strategy=eval_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "feb45243",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    data_collator=DefaultDataCollator(),\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7090bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.590428</td>\n",
       "      <td>0.155556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=1.1273530721664429, metrics={'train_runtime': 36.3796, 'train_samples_per_second': 0.275, 'train_steps_per_second': 0.027, 'total_flos': 1947673450320.0, 'train_loss': 1.1273530721664429, 'epoch': 1.0})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4d47c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.836464524269104,\n",
       " 'test_f1': 0.18,\n",
       " 'test_runtime': 6.122,\n",
       " 'test_samples_per_second': 1.633,\n",
       " 'test_steps_per_second': 0.163}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_dataset[\"test\"])\n",
    "preds.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "99f43fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "y_true = dataset[\"test\"][\"label\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7fbeea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "    # plot confusion matrix\n",
    "    # fig, ax = plt.subplots(figsize=(len(labels),len(labels)))\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    display.plot(cmap=\"Greens\", values_format=\".2f\", colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(cm)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "14546894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.88888889 0.         0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "cm = plot_confusion_matrix(y_true, y_pred, labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "083fe42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliomarinone/Personal_repos/divedeep-transformers/divedeep/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prfs = plot_prfs(y_true, y_pred, labels=label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
